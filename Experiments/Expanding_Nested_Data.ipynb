{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b56456f-9ae6-4dde-8296-d64a7b45fe51",
   "metadata": {},
   "source": [
    "# Notebook to extract the various nested data within a CSV file via a \"strong-arm\" methodology for later use in a Kaggle Competition building Recommender Systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33765826-219c-42ce-866f-07073246b08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import time\n",
    "from tqdm.notebook import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b1f3b0-feb9-4abd-bbd7-c71c111ecfde",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Going to start by expanding the Metadata CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5758f10-e37a-4f44-ba58-2937c1815dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_nested_data_metadata():\n",
    "    '''Function to Retrieve the nested data in the Metadata file'''\n",
    "    \n",
    "    df = pd.read_csv(\"movies_metadata.csv\")\n",
    "    \n",
    "    # Creating column names to account for the amount of sub-categories within each entry\n",
    "    col_names = ['genre_id_1', 'genre_name_1',\n",
    "                 'genre_id_2', 'genre_name_2', \n",
    "                 'genre_id_3', 'genre_name_3', \n",
    "                 'genre_id_4', 'genre_name_4', \n",
    "                 'genre_id_5', 'genre_name_5', \n",
    "                 'genre_id_6', 'genre_name_6', \n",
    "                 'genre_id_7', 'genre_name_7',\n",
    "                 'genre_id_8', 'genre_name_8']\n",
    "    \n",
    "    # Adding those columns to the dataframe\n",
    "    df = df.reindex(columns = df.columns.tolist() + col_names)\n",
    "    \n",
    "    # Iterating through the dataframe with the iterrows method (its kinda like enumerate for DF's), \n",
    "    # using tqdm as a timer. Index from the \"enumeration\" is helpful for multi-indexing later.\n",
    "    for index, row in tqdm(df.iterrows(), desc = 'Genres'):\n",
    "        \n",
    "        # Using ast library to evaluate a string formatted as a dictionary, which basically typecasts. \n",
    "        ## ast library works better than python's eval method IMO.\n",
    "        genre_data = ast.literal_eval(row[3])\n",
    "        \n",
    "        # Using enumerate here to be able to perform efficient multi-indexing.\n",
    "        for counter, dictionary in enumerate(genre_data, start = 1):\n",
    "            \n",
    "            # By using a dict based for loop, and if/else block makes this multi-indexing easier, and allows\n",
    "            # for us to easily assign values to DF rows based on our conditional. NOTE: df.loc is the best\n",
    "            # way to multi-index through a DF that I have found. (had errors trying to use list-like multi-indexing,\n",
    "            # (ie) df['col']['index'])\n",
    "            for key, value in dictionary.items():\n",
    "                if key == 'id':\n",
    "                    df.loc[index, f'genre_id_{counter}'] = value\n",
    "\n",
    "                elif key == 'name':\n",
    "                    df.loc[index, f'genre_name_{counter}'] = value\n",
    "\n",
    "    # Creating column names to account for the amount of sub-categories within each entry\n",
    "    col_names = ['collection_id', 'part_of_collection']\n",
    "    \n",
    "    # Adding those columns to the dataframe\n",
    "    df = df.reindex(columns = df.columns.tolist() + col_names)\n",
    "    \n",
    "    # Iterating through the dataframe with the iterrows method, using tqdm as a timer. Don't need to multi-index this time.\n",
    "    for index, row in tqdm(df.iterrows(), desc = 'Belongs to Collection'):\n",
    "        \n",
    "        # Using a try/ except suite since ast's eval methods throw an error for the various NaN entries in the column.\n",
    "        try:\n",
    "            \n",
    "            # Using ast library to evaluate a string formatted as a dictionary, which basically typecasts. \n",
    "            ## ast library works better than python's eval method IMO.\n",
    "            collection_data = ast.literal_eval(row[1])\n",
    "            \n",
    "            # Same idea here with the key, value for loop, making it easier to assign specific cells.\n",
    "            for key, value in collection_data.items():\n",
    "   \n",
    "                if key == 'id':\n",
    "                    df.loc[index, 'collection_id'] = value\n",
    "\n",
    "                elif key == 'name':\n",
    "                    df.loc[index, 'part_of_collection'] = value\n",
    "        \n",
    "        # Here the pass statement is just making it so that we skip over each row with NaN values\n",
    "        except ValueError:\n",
    "            pass\n",
    "    \n",
    "    # Returning our expanded dataframe!\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "075c1d1d-f488-4915-938d-d067e0949ab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47e1d7d994e54c62961525a2c855f3fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Genres: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce879bd9724643e5b957c2c481e1fda3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Belongs to Collection: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metadata_df = retrieve_nested_data_metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e450b5bd-0c89-4eb1-976c-058c029c6a90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adult</th>\n",
       "      <th>belongs_to_collection</th>\n",
       "      <th>budget</th>\n",
       "      <th>genres</th>\n",
       "      <th>homepage</th>\n",
       "      <th>id</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>original_language</th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "      <th>...</th>\n",
       "      <th>genre_id_5</th>\n",
       "      <th>genre_name_5</th>\n",
       "      <th>genre_id_6</th>\n",
       "      <th>genre_name_6</th>\n",
       "      <th>genre_id_7</th>\n",
       "      <th>genre_name_7</th>\n",
       "      <th>genre_id_8</th>\n",
       "      <th>genre_name_8</th>\n",
       "      <th>collection_id</th>\n",
       "      <th>part_of_collection</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 10194, 'name': 'Toy Story Collection', ...</td>\n",
       "      <td>30000000</td>\n",
       "      <td>[{'id': 16, 'name': 'Animation'}, {'id': 35, '...</td>\n",
       "      <td>http://toystory.disney.com/toy-story</td>\n",
       "      <td>1</td>\n",
       "      <td>tt0114709</td>\n",
       "      <td>en</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10194.0</td>\n",
       "      <td>Toy Story Collection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65000000</td>\n",
       "      <td>[{'id': 12, 'name': 'Adventure'}, {'id': 14, '...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>tt0113497</td>\n",
       "      <td>en</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>When siblings Judy and Peter discover an encha...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 119050, 'name': 'Grumpy Old Men Collect...</td>\n",
       "      <td>0</td>\n",
       "      <td>[{'id': 10749, 'name': 'Romance'}, {'id': 35, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>tt0113228</td>\n",
       "      <td>en</td>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>A family wedding reignites the ancient feud be...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>119050.0</td>\n",
       "      <td>Grumpy Old Men Collection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16000000</td>\n",
       "      <td>[{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>tt0114885</td>\n",
       "      <td>en</td>\n",
       "      <td>Waiting to Exhale</td>\n",
       "      <td>Cheated on, mistreated and stepped on, the wom...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 96871, 'name': 'Father of the Bride Col...</td>\n",
       "      <td>0</td>\n",
       "      <td>[{'id': 35, 'name': 'Comedy'}]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>tt0113041</td>\n",
       "      <td>en</td>\n",
       "      <td>Father of the Bride Part II</td>\n",
       "      <td>Just when George Banks has recovered from his ...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96871.0</td>\n",
       "      <td>Father of the Bride Collection</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   adult                              belongs_to_collection    budget  \\\n",
       "0  False  {'id': 10194, 'name': 'Toy Story Collection', ...  30000000   \n",
       "1  False                                                NaN  65000000   \n",
       "2  False  {'id': 119050, 'name': 'Grumpy Old Men Collect...         0   \n",
       "3  False                                                NaN  16000000   \n",
       "4  False  {'id': 96871, 'name': 'Father of the Bride Col...         0   \n",
       "\n",
       "                                              genres  \\\n",
       "0  [{'id': 16, 'name': 'Animation'}, {'id': 35, '...   \n",
       "1  [{'id': 12, 'name': 'Adventure'}, {'id': 14, '...   \n",
       "2  [{'id': 10749, 'name': 'Romance'}, {'id': 35, ...   \n",
       "3  [{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...   \n",
       "4                     [{'id': 35, 'name': 'Comedy'}]   \n",
       "\n",
       "                               homepage  id    imdb_id original_language  \\\n",
       "0  http://toystory.disney.com/toy-story   1  tt0114709                en   \n",
       "1                                   NaN   2  tt0113497                en   \n",
       "2                                   NaN   3  tt0113228                en   \n",
       "3                                   NaN   4  tt0114885                en   \n",
       "4                                   NaN   5  tt0113041                en   \n",
       "\n",
       "                original_title  \\\n",
       "0                    Toy Story   \n",
       "1                      Jumanji   \n",
       "2             Grumpier Old Men   \n",
       "3            Waiting to Exhale   \n",
       "4  Father of the Bride Part II   \n",
       "\n",
       "                                            overview  ...  genre_id_5  \\\n",
       "0  Led by Woody, Andy's toys live happily in his ...  ...         NaN   \n",
       "1  When siblings Judy and Peter discover an encha...  ...         NaN   \n",
       "2  A family wedding reignites the ancient feud be...  ...         NaN   \n",
       "3  Cheated on, mistreated and stepped on, the wom...  ...         NaN   \n",
       "4  Just when George Banks has recovered from his ...  ...         NaN   \n",
       "\n",
       "  genre_name_5 genre_id_6 genre_name_6 genre_id_7  genre_name_7  genre_id_8  \\\n",
       "0          NaN        NaN          NaN        NaN           NaN         NaN   \n",
       "1          NaN        NaN          NaN        NaN           NaN         NaN   \n",
       "2          NaN        NaN          NaN        NaN           NaN         NaN   \n",
       "3          NaN        NaN          NaN        NaN           NaN         NaN   \n",
       "4          NaN        NaN          NaN        NaN           NaN         NaN   \n",
       "\n",
       "  genre_name_8 collection_id              part_of_collection  \n",
       "0          NaN       10194.0            Toy Story Collection  \n",
       "1          NaN           NaN                             NaN  \n",
       "2          NaN      119050.0       Grumpy Old Men Collection  \n",
       "3          NaN           NaN                             NaN  \n",
       "4          NaN       96871.0  Father of the Bride Collection  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfba89c-9432-46d1-a843-4b61ede7726d",
   "metadata": {},
   "source": [
    "### Below here we just have some extremely basic EDA to see what the results look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "3acbdaeb-a5a6-492c-a88a-d517762ac768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genre_id_1</th>\n",
       "      <th>genre_name_1</th>\n",
       "      <th>genre_id_2</th>\n",
       "      <th>genre_name_2</th>\n",
       "      <th>genre_id_3</th>\n",
       "      <th>genre_name_3</th>\n",
       "      <th>genre_id_4</th>\n",
       "      <th>genre_name_4</th>\n",
       "      <th>genre_id_5</th>\n",
       "      <th>genre_name_5</th>\n",
       "      <th>genre_id_6</th>\n",
       "      <th>genre_name_6</th>\n",
       "      <th>genre_id_7</th>\n",
       "      <th>genre_name_7</th>\n",
       "      <th>genre_id_8</th>\n",
       "      <th>genre_name_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.0</td>\n",
       "      <td>Animation</td>\n",
       "      <td>35.0</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>10751.0</td>\n",
       "      <td>Family</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.0</td>\n",
       "      <td>Adventure</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Fantasy</td>\n",
       "      <td>10751.0</td>\n",
       "      <td>Family</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10749.0</td>\n",
       "      <td>Romance</td>\n",
       "      <td>35.0</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>18.0</td>\n",
       "      <td>Drama</td>\n",
       "      <td>10749.0</td>\n",
       "      <td>Romance</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   genre_id_1 genre_name_1  genre_id_2 genre_name_2  genre_id_3 genre_name_3  \\\n",
       "0        16.0    Animation        35.0       Comedy     10751.0       Family   \n",
       "1        12.0    Adventure        14.0      Fantasy     10751.0       Family   \n",
       "2     10749.0      Romance        35.0       Comedy         NaN          NaN   \n",
       "3        35.0       Comedy        18.0        Drama     10749.0      Romance   \n",
       "4        35.0       Comedy         NaN          NaN         NaN          NaN   \n",
       "\n",
       "   genre_id_4 genre_name_4  genre_id_5 genre_name_5  genre_id_6 genre_name_6  \\\n",
       "0         NaN          NaN         NaN          NaN         NaN          NaN   \n",
       "1         NaN          NaN         NaN          NaN         NaN          NaN   \n",
       "2         NaN          NaN         NaN          NaN         NaN          NaN   \n",
       "3         NaN          NaN         NaN          NaN         NaN          NaN   \n",
       "4         NaN          NaN         NaN          NaN         NaN          NaN   \n",
       "\n",
       "   genre_id_7 genre_name_7  genre_id_8 genre_name_8  \n",
       "0         NaN          NaN         NaN          NaN  \n",
       "1         NaN          NaN         NaN          NaN  \n",
       "2         NaN          NaN         NaN          NaN  \n",
       "3         NaN          NaN         NaN          NaN  \n",
       "4         NaN          NaN         NaN          NaN  "
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_cols = ['genre_id_1', 'genre_name_1',\n",
    "                 'genre_id_2', 'genre_name_2', \n",
    "                 'genre_id_3', 'genre_name_3', \n",
    "                 'genre_id_4', 'genre_name_4', \n",
    "                 'genre_id_5', 'genre_name_5', \n",
    "                 'genre_id_6', 'genre_name_6', \n",
    "                 'genre_id_7', 'genre_name_7',\n",
    "                 'genre_id_8', 'genre_name_8']\n",
    "metadata_df[genre_cols].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99bb0d7-5066-4f94-8bb3-eb6324b70118",
   "metadata": {},
   "source": [
    "#### It seems as though it might be worth keeping just 1 & 2 since the rest of the columns have so many missing values. However I left the other columns in to give the option of use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "b45085ab-a961-4fd6-be83-032be4724c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genre_id_1 = 2433\n",
      "genre_name_1 = 2433\n",
      "genre_id_2 = 16974\n",
      "genre_name_2 = 16974\n",
      "genre_id_3 = 31430\n",
      "genre_name_3 = 31430\n",
      "genre_id_4 = 40993\n",
      "genre_name_4 = 40993\n",
      "genre_id_5 = 44366\n",
      "genre_name_5 = 44366\n",
      "genre_id_6 = 45199\n",
      "genre_name_6 = 45199\n",
      "genre_id_7 = 45356\n",
      "genre_name_7 = 45356\n",
      "genre_id_8 = 45380\n",
      "genre_name_8 = 45380\n"
     ]
    }
   ],
   "source": [
    "for col in genre_cols:\n",
    "    print(f\"{col} = {metadata_df[col].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "f680fae2-fad4-4098-b3e0-77765327d164",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>collection_id</th>\n",
       "      <th>part_of_collection</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10194.0</td>\n",
       "      <td>Toy Story Collection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>119050.0</td>\n",
       "      <td>Grumpy Old Men Collection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>96871.0</td>\n",
       "      <td>Father of the Bride Collection</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   collection_id              part_of_collection\n",
       "0        10194.0            Toy Story Collection\n",
       "1            NaN                             NaN\n",
       "2       119050.0       Grumpy Old Men Collection\n",
       "3            NaN                             NaN\n",
       "4        96871.0  Father of the Bride Collection"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection_cols = ['collection_id', 'part_of_collection']\n",
    "metadata_df[collection_cols].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bb2d80-b41c-403c-8852-dddf612b0f2d",
   "metadata": {},
   "source": [
    "#### It looks like nearly half of the data entries for \"belongs to collection\" are NaN values. I would be intrigued to see wether or not leaving these in positively or negatively effects our various model's performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "022eaeb3-992f-42fe-b911-aa391e714407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collection_id = 40897\n",
      "part_of_collection = 40897\n"
     ]
    }
   ],
   "source": [
    "for col in collection_cols:\n",
    "    print(f\"{col} = {metadata_df[col].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a10eeb-6aeb-4e0e-9015-118bfbcadd8c",
   "metadata": {},
   "source": [
    "### Now, just dropping the original, un-expanded columns and saving to CSV for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "6a6271ef-28a1-4837-8336-4d34e963cbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = ['belongs_to_collection', 'genres']\n",
    "metadata_df = metadata_df.drop(columns = to_drop, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "edb7e87c-bf56-4329-8e44-e842bd59171f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adult</th>\n",
       "      <th>budget</th>\n",
       "      <th>homepage</th>\n",
       "      <th>id</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>original_language</th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "      <th>popularity</th>\n",
       "      <th>poster_path</th>\n",
       "      <th>...</th>\n",
       "      <th>genre_id_5</th>\n",
       "      <th>genre_name_5</th>\n",
       "      <th>genre_id_6</th>\n",
       "      <th>genre_name_6</th>\n",
       "      <th>genre_id_7</th>\n",
       "      <th>genre_name_7</th>\n",
       "      <th>genre_id_8</th>\n",
       "      <th>genre_name_8</th>\n",
       "      <th>collection_id</th>\n",
       "      <th>part_of_collection</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>30000000</td>\n",
       "      <td>http://toystory.disney.com/toy-story</td>\n",
       "      <td>1</td>\n",
       "      <td>tt0114709</td>\n",
       "      <td>en</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
       "      <td>21.946943</td>\n",
       "      <td>/rhIRbceoE9lR4veEXuwCC2wARtG.jpg</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10194.0</td>\n",
       "      <td>Toy Story Collection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>65000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>tt0113497</td>\n",
       "      <td>en</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>When siblings Judy and Peter discover an encha...</td>\n",
       "      <td>17.015539</td>\n",
       "      <td>/vzmL6fP7aPKNKPRTFnZmiUfciyV.jpg</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>tt0113228</td>\n",
       "      <td>en</td>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>A family wedding reignites the ancient feud be...</td>\n",
       "      <td>11.712900</td>\n",
       "      <td>/6ksm1sjKMFLbO7UY2i6G1ju9SML.jpg</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>119050.0</td>\n",
       "      <td>Grumpy Old Men Collection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>16000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>tt0114885</td>\n",
       "      <td>en</td>\n",
       "      <td>Waiting to Exhale</td>\n",
       "      <td>Cheated on, mistreated and stepped on, the wom...</td>\n",
       "      <td>3.859495</td>\n",
       "      <td>/16XOMpEaLWkrcPqSQqhTmeJuqQl.jpg</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>tt0113041</td>\n",
       "      <td>en</td>\n",
       "      <td>Father of the Bride Part II</td>\n",
       "      <td>Just when George Banks has recovered from his ...</td>\n",
       "      <td>8.387519</td>\n",
       "      <td>/e64sOI48hQXyru7naBFyssKFxVd.jpg</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96871.0</td>\n",
       "      <td>Father of the Bride Collection</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   adult    budget                              homepage  id    imdb_id  \\\n",
       "0  False  30000000  http://toystory.disney.com/toy-story   1  tt0114709   \n",
       "1  False  65000000                                   NaN   2  tt0113497   \n",
       "2  False         0                                   NaN   3  tt0113228   \n",
       "3  False  16000000                                   NaN   4  tt0114885   \n",
       "4  False         0                                   NaN   5  tt0113041   \n",
       "\n",
       "  original_language               original_title  \\\n",
       "0                en                    Toy Story   \n",
       "1                en                      Jumanji   \n",
       "2                en             Grumpier Old Men   \n",
       "3                en            Waiting to Exhale   \n",
       "4                en  Father of the Bride Part II   \n",
       "\n",
       "                                            overview  popularity  \\\n",
       "0  Led by Woody, Andy's toys live happily in his ...   21.946943   \n",
       "1  When siblings Judy and Peter discover an encha...   17.015539   \n",
       "2  A family wedding reignites the ancient feud be...   11.712900   \n",
       "3  Cheated on, mistreated and stepped on, the wom...    3.859495   \n",
       "4  Just when George Banks has recovered from his ...    8.387519   \n",
       "\n",
       "                        poster_path  ... genre_id_5 genre_name_5 genre_id_6  \\\n",
       "0  /rhIRbceoE9lR4veEXuwCC2wARtG.jpg  ...        NaN          NaN        NaN   \n",
       "1  /vzmL6fP7aPKNKPRTFnZmiUfciyV.jpg  ...        NaN          NaN        NaN   \n",
       "2  /6ksm1sjKMFLbO7UY2i6G1ju9SML.jpg  ...        NaN          NaN        NaN   \n",
       "3  /16XOMpEaLWkrcPqSQqhTmeJuqQl.jpg  ...        NaN          NaN        NaN   \n",
       "4  /e64sOI48hQXyru7naBFyssKFxVd.jpg  ...        NaN          NaN        NaN   \n",
       "\n",
       "   genre_name_6  genre_id_7 genre_name_7 genre_id_8 genre_name_8  \\\n",
       "0           NaN         NaN          NaN        NaN          NaN   \n",
       "1           NaN         NaN          NaN        NaN          NaN   \n",
       "2           NaN         NaN          NaN        NaN          NaN   \n",
       "3           NaN         NaN          NaN        NaN          NaN   \n",
       "4           NaN         NaN          NaN        NaN          NaN   \n",
       "\n",
       "  collection_id              part_of_collection  \n",
       "0       10194.0            Toy Story Collection  \n",
       "1           NaN                             NaN  \n",
       "2      119050.0       Grumpy Old Men Collection  \n",
       "3           NaN                             NaN  \n",
       "4       96871.0  Father of the Bride Collection  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "aa3bfd86-1485-46f5-8f49-f80df7dd2a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df.to_csv(\"metadata_expanded.csv\", encoding = 'utf-8', ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b918a09-22ad-4cc6-bdc9-468b61889bc1",
   "metadata": {},
   "source": [
    "## Moving on to the Keywords CSV file!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bef3392d-37e4-4d57-ad26-128b85592fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "from tqdm import tqdm\n",
    "\n",
    "def retrieve_first_10_keywords():\n",
    "    '''Function to retrieve the first 10 keywords for each movie in the Keywords file'''\n",
    "    \n",
    "    df = pd.read_csv(\"movies_keywords.csv\")\n",
    "    \n",
    "    # Creating column names to account for the amount of sub-categories within each entry\n",
    "    col_names = [f'keyword_id_{i}' for i in range(1, 11)]\n",
    "    col_names += [f'keyword_name_{i}' for i in range(1, 11)]\n",
    "    \n",
    "    # Creating a list of dictionaries to store the keyword data\n",
    "    keyword_list = []\n",
    "    \n",
    "    # Iterating through the dataframe with the iterrows method (its kinda like enumerate for DF's), \n",
    "    # using tqdm as a timer. Index from the \"enumeration\" is helpful for multi-indexing later.\n",
    "    for index, row in tqdm(df.iterrows(), desc='keywords'):\n",
    "        \n",
    "        # Using ast library to evaluate a string formatted as a dictionary, which basically typecasts. \n",
    "        ## ast library works better than python's eval method IMO.\n",
    "        keyword_data = ast.literal_eval(row[1])\n",
    "        \n",
    "        # Using enumerate here to be able to perform efficient multi-indexing.\n",
    "        keywords_dict = {}\n",
    "        for counter, dictionary in enumerate(keyword_data[:10], start=1):\n",
    "            \n",
    "            # Adding the \"id\" and \"name\" keys to a dictionary for each keyword\n",
    "            keywords_dict[f'keyword_id_{counter}'] = dictionary.get('id')\n",
    "            keywords_dict[f'keyword_name_{counter}'] = dictionary.get('name')\n",
    "            \n",
    "        # Appending the dictionary to the keyword list\n",
    "        keyword_list.append(keywords_dict)\n",
    "    \n",
    "    # Creating a new dataframe from the keyword list\n",
    "    keyword_df = pd.DataFrame(keyword_list, columns=col_names)\n",
    "    \n",
    "    # Concatenating the original dataframe with the keyword dataframe\n",
    "    df = pd.concat([df[['id', 'title']], keyword_df], axis=1)\n",
    "    \n",
    "    # Returning the expanded dataframe\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "92b61b18-d477-4e0c-ba7a-50973572ddda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "keywords: 961it [00:00, 1519.56it/s]C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_name_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_id_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_name_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_id_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_name_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_id_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_name_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_id_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_name_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_id_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_name_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_id_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_name_{counter}'] = value\n",
      "keywords: 3188it [00:02, 1642.43it/s]C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_id_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_name_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_id_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_name_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_id_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_name_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_id_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_name_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_id_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_name_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_id_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_name_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_id_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_name_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_id_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_name_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_id_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_name_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_id_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_name_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_id_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_name_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_id_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_name_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_id_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_name_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_id_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_name_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_id_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_name_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_id_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_name_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_id_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_name_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_id_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_name_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_id_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_name_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_id_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_name_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_id_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_name_{counter}'] = value\n",
      "keywords: 9212it [00:05, 2249.74it/s]C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_id_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_name_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_id_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_name_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_id_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_name_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_id_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_name_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_id_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_name_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_id_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_name_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_id_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_name_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_id_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_name_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_id_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_name_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_id_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_name_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_id_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_name_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_id_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_name_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_id_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_name_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_id_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_name_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_id_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_name_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_id_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_name_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_id_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_name_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_id_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_name_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_id_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_name_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_id_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_name_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_id_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_name_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_id_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_name_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_id_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_name_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_id_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_name_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_id_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_name_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_id_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_name_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_id_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_name_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_id_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_name_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_id_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_name_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_id_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_name_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_id_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_name_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_id_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_name_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_id_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_name_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_id_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_name_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_id_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_name_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_id_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_name_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_id_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_name_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_id_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_name_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_id_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_name_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_id_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_name_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_id_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_name_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_id_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_name_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_id_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_name_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_id_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_name_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_id_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_name_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_id_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_name_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_id_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_name_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_id_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_name_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_id_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_name_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_id_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_name_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_id_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_name_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_id_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_name_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_id_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_name_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_id_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_name_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_id_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_name_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_id_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_name_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_id_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_name_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_id_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_name_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_id_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_name_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_id_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_name_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_id_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_name_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_id_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_name_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_id_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_name_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_id_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_name_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_id_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_name_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_id_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_name_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_id_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_name_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_id_{counter}'] = value\n",
      "C:\\Users\\rache\\AppData\\Local\\Temp\\ipykernel_22656\\1020484114.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[index, f'keyword_name_{counter}'] = value\n",
      "keywords: 46338it [00:16, 2763.29it/s]\n"
     ]
    }
   ],
   "source": [
    "keyword_df = retrieve_nested_data_keywords()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "96ebbb7f-03ad-4057-a405-89cab6edf258",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keywords</th>\n",
       "      <th>keyword_id_1</th>\n",
       "      <th>keyword_name_1</th>\n",
       "      <th>keyword_id_2</th>\n",
       "      <th>keyword_name_2</th>\n",
       "      <th>keyword_id_3</th>\n",
       "      <th>keyword_name_3</th>\n",
       "      <th>keyword_id_4</th>\n",
       "      <th>keyword_name_4</th>\n",
       "      <th>...</th>\n",
       "      <th>keyword_id_145</th>\n",
       "      <th>keyword_name_145</th>\n",
       "      <th>keyword_id_146</th>\n",
       "      <th>keyword_name_146</th>\n",
       "      <th>keyword_id_147</th>\n",
       "      <th>keyword_name_147</th>\n",
       "      <th>keyword_id_148</th>\n",
       "      <th>keyword_name_148</th>\n",
       "      <th>keyword_id_149</th>\n",
       "      <th>keyword_name_149</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[{'id': 931, 'name': 'jealousy'}, {'id': 4290,...</td>\n",
       "      <td>931.0</td>\n",
       "      <td>jealousy</td>\n",
       "      <td>4290.0</td>\n",
       "      <td>toy</td>\n",
       "      <td>5202.0</td>\n",
       "      <td>boy</td>\n",
       "      <td>6054.0</td>\n",
       "      <td>friendship</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[{'id': 10090, 'name': 'board game'}, {'id': 1...</td>\n",
       "      <td>10090.0</td>\n",
       "      <td>board game</td>\n",
       "      <td>10941.0</td>\n",
       "      <td>disappearance</td>\n",
       "      <td>15101.0</td>\n",
       "      <td>based on children's book</td>\n",
       "      <td>33467.0</td>\n",
       "      <td>new home</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[{'id': 1495, 'name': 'fishing'}, {'id': 12392...</td>\n",
       "      <td>1495.0</td>\n",
       "      <td>fishing</td>\n",
       "      <td>12392.0</td>\n",
       "      <td>best friend</td>\n",
       "      <td>179431.0</td>\n",
       "      <td>duringcreditsstinger</td>\n",
       "      <td>208510.0</td>\n",
       "      <td>old men</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[{'id': 818, 'name': 'based on novel'}, {'id':...</td>\n",
       "      <td>818.0</td>\n",
       "      <td>based on novel</td>\n",
       "      <td>10131.0</td>\n",
       "      <td>interracial relationship</td>\n",
       "      <td>14768.0</td>\n",
       "      <td>single mother</td>\n",
       "      <td>15160.0</td>\n",
       "      <td>divorce</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[{'id': 1009, 'name': 'baby'}, {'id': 1599, 'n...</td>\n",
       "      <td>1009.0</td>\n",
       "      <td>baby</td>\n",
       "      <td>1599.0</td>\n",
       "      <td>midlife crisis</td>\n",
       "      <td>2246.0</td>\n",
       "      <td>confidence</td>\n",
       "      <td>4995.0</td>\n",
       "      <td>aging</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                           keywords  keyword_id_1  \\\n",
       "0   1  [{'id': 931, 'name': 'jealousy'}, {'id': 4290,...         931.0   \n",
       "1   2  [{'id': 10090, 'name': 'board game'}, {'id': 1...       10090.0   \n",
       "2   3  [{'id': 1495, 'name': 'fishing'}, {'id': 12392...        1495.0   \n",
       "3   4  [{'id': 818, 'name': 'based on novel'}, {'id':...         818.0   \n",
       "4   5  [{'id': 1009, 'name': 'baby'}, {'id': 1599, 'n...        1009.0   \n",
       "\n",
       "   keyword_name_1  keyword_id_2            keyword_name_2  keyword_id_3  \\\n",
       "0        jealousy        4290.0                       toy        5202.0   \n",
       "1      board game       10941.0             disappearance       15101.0   \n",
       "2         fishing       12392.0               best friend      179431.0   \n",
       "3  based on novel       10131.0  interracial relationship       14768.0   \n",
       "4            baby        1599.0            midlife crisis        2246.0   \n",
       "\n",
       "             keyword_name_3  keyword_id_4 keyword_name_4  ...  keyword_id_145  \\\n",
       "0                       boy        6054.0     friendship  ...             NaN   \n",
       "1  based on children's book       33467.0       new home  ...             NaN   \n",
       "2      duringcreditsstinger      208510.0        old men  ...             NaN   \n",
       "3             single mother       15160.0        divorce  ...             NaN   \n",
       "4                confidence        4995.0          aging  ...             NaN   \n",
       "\n",
       "  keyword_name_145  keyword_id_146 keyword_name_146  keyword_id_147  \\\n",
       "0              NaN             NaN              NaN             NaN   \n",
       "1              NaN             NaN              NaN             NaN   \n",
       "2              NaN             NaN              NaN             NaN   \n",
       "3              NaN             NaN              NaN             NaN   \n",
       "4              NaN             NaN              NaN             NaN   \n",
       "\n",
       "  keyword_name_147  keyword_id_148 keyword_name_148  keyword_id_149  \\\n",
       "0              NaN             NaN              NaN             NaN   \n",
       "1              NaN             NaN              NaN             NaN   \n",
       "2              NaN             NaN              NaN             NaN   \n",
       "3              NaN             NaN              NaN             NaN   \n",
       "4              NaN             NaN              NaN             NaN   \n",
       "\n",
       "  keyword_name_149  \n",
       "0              NaN  \n",
       "1              NaN  \n",
       "2              NaN  \n",
       "3              NaN  \n",
       "4              NaN  \n",
       "\n",
       "[5 rows x 300 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyword_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab2f547-2736-4e72-b7a2-701e5c1979e1",
   "metadata": {},
   "source": [
    "#### ^^ Got some fragmentation warnings when running the above code. ^^ However, the end result is just fine. I would like to understand why, but its beyond my scope of understanding.\n",
    "\n",
    "#### The Warning Itself:\n",
    "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
    "  df.loc[index, f'keyword_name_{counter}'] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "c1be1e7d-2536-4d32-bf1c-b3eb144a8b74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword_id_1</th>\n",
       "      <th>keyword_name_1</th>\n",
       "      <th>keyword_id_2</th>\n",
       "      <th>keyword_name_2</th>\n",
       "      <th>keyword_id_3</th>\n",
       "      <th>keyword_name_3</th>\n",
       "      <th>keyword_id_4</th>\n",
       "      <th>keyword_name_4</th>\n",
       "      <th>keyword_id_5</th>\n",
       "      <th>keyword_name_5</th>\n",
       "      <th>keyword_id_6</th>\n",
       "      <th>keyword_name_6</th>\n",
       "      <th>keyword_id_7</th>\n",
       "      <th>keyword_name_7</th>\n",
       "      <th>keyword_id_8</th>\n",
       "      <th>keyword_name_8</th>\n",
       "      <th>keyword_id_9</th>\n",
       "      <th>keyword_name_9</th>\n",
       "      <th>keyword_id_10</th>\n",
       "      <th>keyword_name_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>931.0</td>\n",
       "      <td>jealousy</td>\n",
       "      <td>4290.0</td>\n",
       "      <td>toy</td>\n",
       "      <td>5202.0</td>\n",
       "      <td>boy</td>\n",
       "      <td>6054.0</td>\n",
       "      <td>friendship</td>\n",
       "      <td>9713.0</td>\n",
       "      <td>friends</td>\n",
       "      <td>9823.0</td>\n",
       "      <td>rivalry</td>\n",
       "      <td>165503.0</td>\n",
       "      <td>boy next door</td>\n",
       "      <td>170722.0</td>\n",
       "      <td>new toy</td>\n",
       "      <td>187065.0</td>\n",
       "      <td>toy comes to life</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10090.0</td>\n",
       "      <td>board game</td>\n",
       "      <td>10941.0</td>\n",
       "      <td>disappearance</td>\n",
       "      <td>15101.0</td>\n",
       "      <td>based on children's book</td>\n",
       "      <td>33467.0</td>\n",
       "      <td>new home</td>\n",
       "      <td>158086.0</td>\n",
       "      <td>recluse</td>\n",
       "      <td>158091.0</td>\n",
       "      <td>giant insect</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1495.0</td>\n",
       "      <td>fishing</td>\n",
       "      <td>12392.0</td>\n",
       "      <td>best friend</td>\n",
       "      <td>179431.0</td>\n",
       "      <td>duringcreditsstinger</td>\n",
       "      <td>208510.0</td>\n",
       "      <td>old men</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>818.0</td>\n",
       "      <td>based on novel</td>\n",
       "      <td>10131.0</td>\n",
       "      <td>interracial relationship</td>\n",
       "      <td>14768.0</td>\n",
       "      <td>single mother</td>\n",
       "      <td>15160.0</td>\n",
       "      <td>divorce</td>\n",
       "      <td>33455.0</td>\n",
       "      <td>chick flick</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1009.0</td>\n",
       "      <td>baby</td>\n",
       "      <td>1599.0</td>\n",
       "      <td>midlife crisis</td>\n",
       "      <td>2246.0</td>\n",
       "      <td>confidence</td>\n",
       "      <td>4995.0</td>\n",
       "      <td>aging</td>\n",
       "      <td>5600.0</td>\n",
       "      <td>daughter</td>\n",
       "      <td>10707.0</td>\n",
       "      <td>mother daughter relationship</td>\n",
       "      <td>13149.0</td>\n",
       "      <td>pregnancy</td>\n",
       "      <td>33358.0</td>\n",
       "      <td>contraception</td>\n",
       "      <td>170521.0</td>\n",
       "      <td>gynecologist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   keyword_id_1  keyword_name_1  keyword_id_2            keyword_name_2  \\\n",
       "0         931.0        jealousy        4290.0                       toy   \n",
       "1       10090.0      board game       10941.0             disappearance   \n",
       "2        1495.0         fishing       12392.0               best friend   \n",
       "3         818.0  based on novel       10131.0  interracial relationship   \n",
       "4        1009.0            baby        1599.0            midlife crisis   \n",
       "\n",
       "   keyword_id_3            keyword_name_3  keyword_id_4 keyword_name_4  \\\n",
       "0        5202.0                       boy        6054.0     friendship   \n",
       "1       15101.0  based on children's book       33467.0       new home   \n",
       "2      179431.0      duringcreditsstinger      208510.0        old men   \n",
       "3       14768.0             single mother       15160.0        divorce   \n",
       "4        2246.0                confidence        4995.0          aging   \n",
       "\n",
       "   keyword_id_5 keyword_name_5  keyword_id_6                keyword_name_6  \\\n",
       "0        9713.0        friends        9823.0                       rivalry   \n",
       "1      158086.0        recluse      158091.0                  giant insect   \n",
       "2           NaN            NaN           NaN                           NaN   \n",
       "3       33455.0    chick flick           NaN                           NaN   \n",
       "4        5600.0       daughter       10707.0  mother daughter relationship   \n",
       "\n",
       "   keyword_id_7 keyword_name_7  keyword_id_8 keyword_name_8  keyword_id_9  \\\n",
       "0      165503.0  boy next door      170722.0        new toy      187065.0   \n",
       "1           NaN            NaN           NaN            NaN           NaN   \n",
       "2           NaN            NaN           NaN            NaN           NaN   \n",
       "3           NaN            NaN           NaN            NaN           NaN   \n",
       "4       13149.0      pregnancy       33358.0  contraception      170521.0   \n",
       "\n",
       "      keyword_name_9  keyword_id_10 keyword_name_10  \n",
       "0  toy comes to life            NaN             NaN  \n",
       "1                NaN            NaN             NaN  \n",
       "2                NaN            NaN             NaN  \n",
       "3                NaN            NaN             NaN  \n",
       "4       gynecologist            NaN             NaN  "
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyword_col_names = ['keyword_id_1', 'keyword_name_1',\n",
    "                     'keyword_id_2', 'keyword_name_2', \n",
    "                     'keyword_id_3', 'keyword_name_3', \n",
    "                     'keyword_id_4', 'keyword_name_4', \n",
    "                     'keyword_id_5', 'keyword_name_5', \n",
    "                     'keyword_id_6', 'keyword_name_6', \n",
    "                     'keyword_id_7', 'keyword_name_7',\n",
    "                     'keyword_id_8', 'keyword_name_8',\n",
    "                     'keyword_id_9', 'keyword_name_9',\n",
    "                     'keyword_id_10', 'keyword_name_10']\n",
    "keyword_df[keyword_col_names].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b450a785-5874-40bb-8927-03c11038ce00",
   "metadata": {},
   "source": [
    "### Again it looks like the Keywords have a lot of missing values overall. However, hopefully, it is still useful data for our future modelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "29c148ae-87a7-4f9d-95af-d94428bc0d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword_id_1 = 14750\n",
      "keyword_name_1 = 14750\n",
      "keyword_id_2 = 21359\n",
      "keyword_name_2 = 21359\n",
      "keyword_id_3 = 26170\n",
      "keyword_name_3 = 26170\n",
      "keyword_id_4 = 30441\n",
      "keyword_name_4 = 30441\n",
      "keyword_id_5 = 33738\n",
      "keyword_name_5 = 33738\n",
      "keyword_id_6 = 36595\n",
      "keyword_name_6 = 36595\n",
      "keyword_id_7 = 38565\n",
      "keyword_name_7 = 38565\n",
      "keyword_id_8 = 40061\n",
      "keyword_name_8 = 40061\n",
      "keyword_id_9 = 41112\n",
      "keyword_name_9 = 41112\n",
      "keyword_id_10 = 41973\n",
      "keyword_name_10 = 41973\n"
     ]
    }
   ],
   "source": [
    "for col in keyword_col_names:\n",
    "    print(f\"{col} = {keyword_df[col].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cd3c7f-4aa2-477b-8361-a5a2b609d943",
   "metadata": {},
   "source": [
    "### Now, just dropping the original, un-expanded columns and saving to CSV for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "be49486f-2827-4a05-baa3-21cc4ffb6325",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_df = keyword_df.drop(columns = 'keywords', index = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "762f76a9-cd5a-4d6b-8a41-68a79f76d208",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_df.to_csv('keywords_expanded.csv', encoding = 'utf-8', ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e974dc-16d1-4f8a-bfe4-1ddc0c841c08",
   "metadata": {},
   "source": [
    "# And that's it for Rachel's strong-arm method for extracting the nested data! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
